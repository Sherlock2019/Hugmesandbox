#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¦ Asset Appraisal Agent â€” Full E2E Flow (Inputs â†’ Anonymize â†’ AI Appraise â†’ Human Review â†’ Train/Promote)
Author:  Nguyen Dzoan
Version: 2025-10-31

New in this build:
- Stage 1: CSV + evidence (images/PDFs) + manual asset input; synthetic fallback + "why" table
- Stage 2: Explicit anonymization pipeline (RAW & ANON kept)
- Stage 3: AI appraisal with hints (LLM/flavor/model); rule_reasons column explaining metrics met/not met
- Stage 4: Human Review with AIâ†”Human agreement gauge; export feedback CSV
- Stage 5: Training (upload feedback CSVs) â†’ Train candidate â†’ Promote to PRODUCTION
"""

import os, io, re, json, datetime, requests, base64
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PAGE CONFIG + SIDEBAR HIDE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Asset Appraisal Agent", layout="wide")
st.markdown("""
<style>
[data-testid="stSidebar"], section[data-testid="stSidebar"], nav[data-testid="stSidebarNav"] { display:none !important; }
[data-testid="stAppViewContainer"] { margin-left:0 !important; padding-left:0 !important; }
div[data-testid="stMetricValue"] { color:#38bdf8 !important; }
</style>
""", unsafe_allow_html=True)

API_URL = os.getenv("API_URL", "http://localhost:8090")
ASSET_AGENT_IDS = ["asset_appraisal", "asset"]  # first that responds wins

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# NAV
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def render_nav_bar_app():
    stage = st.session_state.get("asset_stage", "login")
    show_home   = stage in ("agents", "credit_agent", "asset_agent", "login", "asset_flow")
    show_agents = stage not in ("landing", "agents")
    if not (show_home or show_agents): return
    c1, c2, _ = st.columns([1,1,6])
    with c1:
        if show_home and st.button("ğŸ  Back to Home", key=f"btn_home_asset_{stage}"):
            st.session_state["asset_stage"] = "landing"; st.rerun()
    with c2:
        if show_agents and st.button("ğŸ¤– Back to Agents", key=f"btn_agents_asset_{stage}"):
            st.session_state["asset_stage"] = "agents"; st.rerun()
    st.markdown("---")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SESSION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ss = st.session_state
ss.setdefault("asset_stage", "login")
ss.setdefault("asset_logged_in", False)
ss.setdefault("asset_user", None)

# Stage caches
ss.setdefault("asset_raw_df", None)     # Stage 1 raw (after CSV/manual merge)
ss.setdefault("asset_evidence", [])     # list of filenames (images/pdfs)
ss.setdefault("asset_anon_df", None)    # Stage 2 anonymized
ss.setdefault("asset_stage2_df", None)  # Stage 3 input (resolved source)
ss.setdefault("asset_ai_df", None)      # Stage 3 AI output
ss.setdefault("asset_selected_model", None)  # trained model path

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# HELPERS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def anonymize_text_cols(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    for col in out.columns:
        if out[col].dtype == "object":
            out[col] = (
                out[col].astype(str)
                .apply(lambda x: re.sub(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+", "[EMAIL]", x))
            )
    return out

def quick_synth(rows: int = 150) -> pd.DataFrame:
    """Generate full asset rows + finance metrics for demo/backup."""
    rng = np.random.default_rng(42)
    cities = [
        ("Hanoi", 21.0285, 105.8542),
        ("HCMC", 10.7769, 106.7009),
        ("Da Nang", 16.0544, 108.2022),
        ("Hue", 16.4637, 107.5909),
        ("Can Tho", 10.0452, 105.7469),
    ]
    df = pd.DataFrame({
        "application_id": [f"APP_{i:04d}" for i in range(1, rows + 1)],
        "asset_id": [f"A{i:04d}" for i in range(1, rows + 1)],
        "asset_type": rng.choice(["House","Apartment","Car","Land","Factory"], rows),
        "age_years": rng.integers(1, 40, rows),
        "market_value": rng.integers(50_000, 2_000_000, rows),
        "condition_score": rng.uniform(0.6, 1.0, rows),
        "legal_penalty": rng.uniform(0.95, 1.0, rows),          # proxy for legal risk adj
        "employment_years": rng.integers(0, 30, rows),
        "credit_history_years": rng.integers(0, 25, rows),
        "delinquencies": rng.integers(0, 6, rows),
        "current_loans": rng.integers(0, 8, rows),
        "loan_amount": rng.integers(10_000, 200_000, rows),
        "customer_type": rng.choice(["bank","non-bank"], rows, p=[0.7,0.3]),
    })
    cdf = pd.DataFrame(cities, columns=["city","lat","lon"])
    df["city"] = rng.choice(cdf["city"], rows)
    df = df.merge(cdf, on="city", how="left")
    df["depreciation_rate"] = (1 - df["condition_score"]) * 100
    df["market_segment"] = np.where(df["market_value"] > 500_000, "High", "Mass")
    # computed metrics to support charts and rules
    df["DTI"] = rng.uniform(0.05, 0.9, rows)
    df["LTV"] = np.clip(df["loan_amount"] / np.maximum(df["market_value"], 1), 0.05, 1.5)
    df["evidence_files"] = [[] for _ in range(rows)]
    return df

def synth_why_table() -> pd.DataFrame:
    return pd.DataFrame([
        {"Metric": "DTI", "Why": "Debt service relative to income â€” proxy for payability."},
        {"Metric": "LTV", "Why": "Loan vs asset value â€” proxy for collateral adequacy."},
        {"Metric": "condition_score", "Why": "Asset physical state impacts fair value/depreciation."},
        {"Metric": "legal_penalty", "Why": "Legal/title flags reduce realizable value."},
        {"Metric": "employment_years / credit_history_years", "Why": "Stability/track record."},
        {"Metric": "delinquencies / current_loans", "Why": "Current risk pressure."},
        {"Metric": "market_segment / city / lat,lon", "Why": "Market & location effects on pricing."},
    ])

# def try_run_asset_agent(csv_bytes: bytes, form_fields: dict, timeout_sec: int = 180):
#     files = {"file": ("asset_verified.csv", io.BytesIO(csv_bytes), "text/csv")}
#     last_error = None
#     for agent_id in ASSET_AGENT_IDS:
#         url = f"{API_URL}/v1/agents/{agent_id}/run"
#         try:
#             resp = requests.post(url, files=files, data=form_fields, timeout=timeout_sec)
#         except Exception as e:
#             last_error = f"Request error for '{agent_id}': {e}"; continue
#         if resp.ok:
#             try:
#                 return True, pd.DataFrame(resp.json())
#             except Exception as e:
#                 return False, f"Parse error for '{agent_id}': {e}\nBody:\n{resp.text}"
#         last_error = f"{resp.status_code} {resp.reason} for '{agent_id}'\nBody:\n{resp.text}"
#     return False, last_error or "Unknown error"
def try_run_asset_agent(csv_bytes: bytes, form_fields: dict, timeout_sec: int = 180):
    """
    Try each known agent id until one works.
    Rebuild the multipart 'file' for every attempt to avoid exhausted streams.
    Returns (ok: bool, DataFrame | error_string)
    """
    errors = []
    for agent_id in ASSET_AGENT_IDS:
        # IMPORTANT: rebuild BytesIO on each attempt
        files = {"file": ("asset_verified.csv", io.BytesIO(csv_bytes), "text/csv")}
        url = f"{API_URL}/v1/agents/{agent_id}/run"
        try:
            resp = requests.post(url, files=files, data=form_fields, timeout=timeout_sec)
        except Exception as e:
            errors.append(f"[{agent_id}] request error: {e}")
            continue

        if resp.ok:
            try:
                return True, pd.DataFrame(resp.json())
            except Exception as e:
                errors.append(f"[{agent_id}] parse error: {e}\nBody:\n{resp.text[:2000]}")
                continue
        else:
            errors.append(f"[{agent_id}] {resp.status_code} {resp.reason}\nBody:\n{resp.text[:2000]}")

    return False, "All agent attempts failed:\n" + "\n\n".join(errors)


# Compute UI rule decision & reasons (used when backend doesn't provide)
def compute_rule_reason(row, mode, thresholds):
    reasons = {}
    # common checks
    reasons["min_emp_years"]   = row.get("employment_years", 0) >= thresholds["min_emp"]
    reasons["min_credit_hist"] = row.get("credit_history_years", 0) >= thresholds["min_hist"]
    reasons["max_delinquencies"] = row.get("delinquencies", 99) <= thresholds["max_delin"]
    reasons["amount_min"] = row.get("loan_amount", 0) >= thresholds["req_min"]
    reasons["amount_max"] = row.get("loan_amount", 10**12) <= thresholds["req_max"]
    # mode-specific
    if mode == "classic":
        reasons["max_dti"] = row.get("DTI", 1.0) <= thresholds["max_dti"]
    else:
        income = row.get("income", row.get("loan_amount", 0) * 1.2)
        compounded = row.get("loan_amount", 0) * (1 + thresholds["monthly_relief"])
        ndi_ratio = income / max(compounded, 1)
        reasons["min_ndi_ratio"] = ndi_ratio >= thresholds["min_ndi_ratio"]
    ok = all(reasons.values())
    return ("approved" if ok else "denied", reasons)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LOGIN
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if ss["asset_stage"] == "login" and not ss["asset_logged_in"]:
    render_nav_bar_app()
    st.title("ğŸ” Login to AI Asset Appraisal Platform")
    c1, c2, c3 = st.columns([1,1,1])
    with c1: user = st.text_input("Username", placeholder="e.g. dzoan")
    with c2: email = st.text_input("Email", placeholder="e.g. dzoan@demo.local")
    with c3: pwd = st.text_input("Password", type="password", placeholder="Enter any password")
    if st.button("Login", key="btn_asset_login", use_container_width=True):
        if user.strip() and email.strip():
            ss["asset_user"] = {"name": user.strip(), "email": email.strip(), "timestamp": datetime.datetime.utcnow().isoformat()}
            ss["asset_logged_in"] = True
            ss["asset_stage"] = "asset_flow"
            st.rerun()
        else:
            st.error("âš ï¸ Please fill all fields before continuing.")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# WORKFLOW
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if ss["asset_logged_in"]:
    render_nav_bar_app()
    st.title("ğŸ›ï¸ Asset Appraisal Agent")
    st.caption(f"E2E flow â€” Inputs â†’ Anonymize â†’ AI â†’ Human Review â†’ Training | ğŸ‘‹ {ss['asset_user']['name']}")

    # Production model banner (shared with credit flow)
    try:
        rmeta = requests.get(f"{API_URL}/v1/training/production_meta", timeout=5)
        if rmeta.status_code == 200 and (rmeta.json().get("has_production")):
            ver = (rmeta.json().get("meta") or {}).get("version", "1.x")
            src = (rmeta.json().get("meta") or {}).get("source", "production")
            #st.success(f"ğŸŸ¢ Production model active â€” version: {ver} â€¢ source: {src}")
            src_txt = src if isinstance(src, str) else json.dumps(src, ensure_ascii=False)
            st.success(f"ğŸŸ¢ Production model active â€” version: {ver} â€¢ source: {src_txt}")

        else:
            st.warning("âš ï¸ No production model promoted yet â€” using baseline.")
    except Exception:
        st.info("â„¹ï¸ Production meta unavailable.")

    # Model & hardware hints
    st.subheader("ğŸ§  Local LLM & Hardware Profile")
    LLM_MODELS = [
        ("Mistral 7B Instruct â€” CPU slow / GPU OK", "mistral:7b-instruct", "CPU 16GB (slow) or GPU â‰¥8GB"),
        ("Phi-3 Mini (3.8B) â€” CPU OK", "phi3:3.8b", "CPU 8GB RAM (fast)"),
        ("Gemma-2 7B â€” CPU slow / GPU OK", "gemma2:7b", "CPU 16GB (slow) or GPU â‰¥8GB"),
        ("LLaMA-3 8B â€” GPU recommended", "llama3:8b-instruct", "GPU â‰¥12GB"),
        ("Qwen2 7B â€” GPU recommended", "qwen2:7b-instruct", "GPU â‰¥12GB"),
        ("Mixtral 8x7B â€” GPU only (big)", "mixtral:8x7b-instruct", "GPU 24â€“48GB"),
    ]
    LLM_LABELS = [l for (l, _, _) in LLM_MODELS]
    LLM_VALUE_BY_LABEL = {l: v for (l, v, _) in LLM_MODELS}
    LLM_HINT_BY_LABEL  = {l: h for (l, _, h) in LLM_MODELS}

    OPENSTACK_FLAVORS = {
        "m4.medium":  "4 vCPU / 8 GB RAM â€” CPU-only small",
        "m8.large":   "8 vCPU / 16 GB RAM â€” CPU-only medium",
        "g1.a10.1":   "8 vCPU / 32 GB RAM + 1Ã—A10 24GB",
        "g1.l40.1":   "16 vCPU / 64 GB RAM + 1Ã—L40 48GB",
        "g2.a100.1":  "24 vCPU / 128 GB RAM + 1Ã—A100 80GB",
    }
    c1, c2 = st.columns([1.2,1])
    with c1:
        model_label = st.selectbox("Local LLM (used for narratives/explanations)", LLM_LABELS, index=0)
        llm_value = LLM_VALUE_BY_LABEL[model_label]
        st.caption(f"Hint: {LLM_HINT_BY_LABEL[model_label]}")
    with c2:
        flavor = st.selectbox("OpenStack flavor / host profile", list(OPENSTACK_FLAVORS.keys()), index=0)
        st.caption(OPENSTACK_FLAVORS[flavor])
    use_llm = st.checkbox("Use LLM narrative (include explanations)", value=False)

    st.divider()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # TABS (1..5)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“¥ 1) Data Input",
        "ğŸ§¹ 2) Anonymize",
        "ğŸ¤– 3) AI Appraisal",
        "ğŸ§‘â€âš–ï¸ 4) Human Review",
        "ğŸ§ª 5) Training (Feedback â†’ Retrain)"
    ])

    # ========== 1) DATA INPUT ==========
    with tab1:
        st.subheader("ğŸ“¥ Stage 1 â€” Provide Asset Data (CSV, evidence files, or manual)")
        left, right = st.columns([1.4, 1])

        with left:
            up_csv = st.file_uploader("Upload Asset CSV", type=["csv"], key="asset_csv")
            evid = st.file_uploader("Attach evidence (images or PDFs, optional)", type=["png","jpg","jpeg","pdf"],
                                    accept_multiple_files=True, key="asset_evidence")
            with st.expander("â• Add manual asset row", expanded=False):
                m1, m2 = st.columns(2)
                asset_type = m1.selectbox("Asset Type", ["House","Apartment","Car","Land","Factory"])
                market_value = m2.number_input("Market Value ($)", 0, 10_000_000, 250_000, step=1_000)
                age_years = m1.number_input("Age (years)", 0, 100, 10)
                loan_amount = m2.number_input("Requested Loan ($)", 0, 10_000_000, 120_000, step=1_000)
                employment_years = m1.number_input("Employment Years", 0, 60, 5)
                credit_hist_years = m2.number_input("Credit History (years)", 0, 50, 6)
                delinq = m1.number_input("Delinquencies", 0, 50, 1)
                curr_loans = m2.number_input("Current Loans", 0, 50, 2)
                city = m1.text_input("City (optional)", "HCMC")
                add_row = st.button("Add manual asset row")
            # Merge inputs
            if st.button("Build Stage 1 dataset (or fallback to synthetic if empty)"):
                rows = []
                if up_csv is not None:
                    try:
                        rows.append(pd.read_csv(up_csv))
                    except Exception as e:
                        st.error(f"CSV parse error: {e}")

                if evid:
                    ss["asset_evidence"] = [f.name for f in evid]

                if add_row:
                    rows.append(pd.DataFrame([{
                        "application_id": f"APP_{datetime.datetime.utcnow().strftime('%H%M%S')}",
                        "asset_id": f"A{datetime.datetime.utcnow().strftime('%M%S')}",
                        "asset_type": asset_type, "market_value": market_value, "age_years": age_years,
                        "loan_amount": loan_amount, "employment_years": employment_years,
                        "credit_history_years": credit_hist_years, "delinquencies": delinq,
                        "current_loans": curr_loans, "city": city
                    }]))

                if len(rows) == 0:
                    df = quick_synth(150)
                    st.info("No inputs provided â€” generated synthetic dataset.")
                    st.dataframe(synth_why_table(), use_container_width=True)
                else:
                    df = pd.concat(rows, ignore_index=True)

                # attach evidence filenames (if any)
                if "evidence_files" not in df.columns:
                    df["evidence_files"] = [ss.get("asset_evidence", []) for _ in range(len(df))]

                ss["asset_raw_df"] = df
                st.success(f"Stage 1 dataset ready. Rows: {len(df)}")
                st.dataframe(df.head(15), use_container_width=True)

        with right:
            st.markdown("#### Generated Metrics â€” What & Why")
            st.dataframe(synth_why_table(), use_container_width=True)

    # ========== 2) ANONYMIZE ==========
    with tab2:
        st.subheader("ğŸ§¹ Stage 2 â€” Anonymize / Sanitize PII")
        if ss["asset_raw_df"] is None:
            st.warning("Build Stage 1 dataset first (tab 1).")
        else:
            if st.button("Run anonymization now"):
                ss["asset_anon_df"] = anonymize_text_cols(ss["asset_raw_df"])
                st.success("Anonymization complete. Saved ANON dataset.")
            if ss["asset_anon_df"] is not None:
                st.dataframe(ss["asset_anon_df"].head(15), use_container_width=True)
                st.download_button("â¬‡ï¸ Download anonymized CSV",
                                   data=ss["asset_anon_df"].to_csv(index=False).encode("utf-8"),
                                   file_name="asset_anonymized.csv", mime="text/csv")

    # ========== 3) AI APPRAISAL ==========
    with tab3:
        st.subheader("ğŸ¤– Stage 3 â€” AI Appraisal & Valuation")
        # Model selection & promote
        trained_dir = os.path.expanduser("~/credit-appraisal-agent-poc/agents/asset_appraisal/models/trained")
        models = []
        if os.path.exists(trained_dir):
            for f in os.listdir(trained_dir):
                if f.endswith(".joblib"):
                    fpath = os.path.join(trained_dir, f)
                    ctime = os.path.getctime(fpath)
                    created = datetime.datetime.fromtimestamp(ctime).strftime("%b %d, %Y %H:%M")
                    models.append((f, fpath, created))
        if models:
            models.sort(key=lambda x: x[2], reverse=True)
            display_names = [f"{m[0]} â€” {m[2]}" for m in models]
            sel_display = st.selectbox("ğŸ“¦ Select trained model", display_names)
            sel_model = models[display_names.index(sel_display)][1]
            st.success(f"âœ… Using model: {os.path.basename(sel_model)}")
            ss["asset_selected_model"] = sel_model
            if st.button("ğŸš€ Promote this model to Production"):
                try:
                    prod_path = os.path.expanduser("~/credit-appraisal-agent-poc/agents/asset_appraisal/models/production/model.joblib")
                    os.makedirs(os.path.dirname(prod_path), exist_ok=True)
                    import shutil; shutil.copy2(sel_model, prod_path)
                    st.success(f"Promoted to production: {os.path.basename(prod_path)}")
                except Exception as e:
                    st.error(f"Promotion failed: {e}")
        else:
            st.warning("No trained models found. You can still run with baseline.")

        # Decision Rule Set (UI, also used to compute reasons if backend omits)
        st.markdown("### âš–ï¸ Decision Rule Set")
        rule_mode = st.radio("Choose rule mode", ["Classic (bank-style metrics)","NDI (Net Disposable Income) â€” simple"],
                             horizontal=True)
        c1, c2 = st.columns(2)
        if rule_mode.startswith("Classic"):
            max_dti = c1.slider("Max Debt-to-Income (DTI)", 0.1, 1.0, 0.45, 0.01)
            min_ndi_ratio = None
        else:
            min_ndi_ratio = c1.slider("Min Income / Compounded Debt Ratio", 0.1, 2.0, 0.35, 0.01)
            max_dti = None
        min_emp = c1.number_input("Min Employment Years", 0, 40, 2)
        min_hist = c1.number_input("Min Credit History (years)", 0, 40, 3)
        max_delin = c1.number_input("Max Delinquencies", 0, 20, 2)
        req_min = c2.number_input("Requested Amount Min ($)", 0, 10_000_000, 1_000, step=500)
        req_max = c2.number_input("Requested Amount Max ($)", 0, 10_000_000, 200_000, step=1_000)
        allowed_terms = c2.multiselect("Allowed Loan Terms (months)", [12,24,36,48,60], default=[12,24,36,48,60])
        monthly_relief = c2.slider("Monthly Debt Relief Factor", 0.0, 1.0, 0.50, 0.01)

        # Choose data source
        src = st.selectbox("Data source for AI run", [
            "Use ANON (from Stage 2)",
            "Use RAW â†’ auto-sanitize",
            "Use synthetic (fallback)",
        ])

        # Resolve df2
        df2 = None
        if src == "Use ANON (from Stage 2)":
            df2 = ss.get("asset_anon_df")
        elif src == "Use RAW â†’ auto-sanitize":
            df2 = anonymize_text_cols(ss.get("asset_raw_df")) if ss.get("asset_raw_df") is not None else None
        else:
            df2 = quick_synth(150)

        if df2 is None:
            st.warning("No dataset available. Build Stage 1 & run anonymization first.")
        else:
            st.dataframe(df2.head(10), use_container_width=True)
            if st.button("ğŸš€ Run AI Appraisal now"):
                csv_bytes = df2.to_csv(index=False).encode("utf-8")
                form_fields = {
                    "use_llm": str(use_llm).lower(),
                    "llm": llm_value,
                    "flavor": flavor,
                    "selected_model": ss.get("asset_selected_model", ""),
                    "agent_name": "asset_appraisal",
                    "rule_mode": "classic" if rule_mode.startswith("Classic") else "ndi",
                    "max_dti": "" if max_dti is None else str(max_dti),
                    "min_ndi_ratio": "" if min_ndi_ratio is None else str(min_ndi_ratio),
                    "min_emp": str(min_emp), "min_hist": str(min_hist),
                    "max_delin": str(max_delin), "req_min": str(req_min), "req_max": str(req_max),
                    "allowed_terms": json.dumps(allowed_terms),
                    "monthly_relief": str(monthly_relief),
                }
                with st.spinner("Calling asset agentâ€¦"):
                    ok, result = try_run_asset_agent(csv_bytes, form_fields=form_fields, timeout_sec=180)
                if not ok:
                    #st.error("âŒ Model API error."); st.code(str(result)[:4000]); st.stop()
                    if not ok:
                        st.error("âŒ Model API error. Tried: " + ", ".join(ASSET_AGENT_IDS))
                        st.code(str(result)[:8000])
                        st.stop()

                df_app = result.copy()

                # Ensure core columns
                if "ai_adjusted" not in df_app.columns and "market_value" in df_app.columns:
                    df_app["ai_adjusted"] = df_app["market_value"]
                df_app.setdefault("confidence", 80.0)
                df_app.setdefault("market_delta", 0.0)

                # Rule reasons: prefer backend; else compute from UI thresholds
                thresholds = {
                    "min_emp": min_emp, "min_hist": min_hist, "max_delin": max_delin,
                    "req_min": req_min, "req_max": req_max,
                    "max_dti": max_dti if max_dti is not None else 1.0,
                    "min_ndi_ratio": min_ndi_ratio if min_ndi_ratio is not None else 0.0,
                    "monthly_relief": monthly_relief,
                }
                if "ai_reasons" not in df_app.columns and "rule_reasons" not in df_app.columns:
                    decs, reas = [], []
                    for _, r in df_app.iterrows():
                        d, rv = compute_rule_reason(r, "classic" if max_dti is not None else "ndi", thresholds)
                        decs.append(d); reas.append(rv)
                    if "decision" not in df_app.columns:
                        df_app["decision"] = decs
                    df_app["rule_reasons"] = reas

                ss["asset_ai_df"] = df_app
                st.success("AI appraisal completed.")
                st.dataframe(df_app.head(15), use_container_width=True)
                st.download_button("â¬‡ï¸ Export AI decisions CSV",
                                   data=df_app.to_csv(index=False).encode("utf-8"),
                                   file_name="ai_asset_decisions.csv", mime="text/csv")

            # Dashboard if we already have results
            if ss.get("asset_ai_df") is not None:
                df_app = ss["asset_ai_df"]
                # KPI Strip
                decision_col = "decision" if "decision" in df_app.columns else "rule_decision"
                if decision_col not in df_app.columns and "rule_reasons" in df_app.columns:
                    df_app[decision_col] = ["approved" if all(v.values()) else "denied"
                                            for v in df_app["rule_reasons"]]
                approved_mask = df_app[decision_col].astype(str).str.lower().eq("approved")
                approval_rate = float(approved_mask.mean() * 100)
                avg_approved = float(df_app.loc[approved_mask, "loan_amount"].mean()) if approved_mask.any() else 0.0
                non_bank_share = float((df_app.get("customer_type", pd.Series(["bank"]*len(df_app))).astype(str)=="non-bank").mean()*100)
                avg_ltv = float((df_app.get("LTV") or pd.Series([0])).mean())
                avg_dti = float((df_app.get("DTI") or pd.Series([0])).mean())
                k1,k2,k3,k4,k5,k6 = st.columns(6)
                k1.metric("Approval Rate", f"{approval_rate:.1f}%", f"{approved_mask.sum()} of {len(df_app)}")
                k2.metric("Avg Approved Amount", f"${avg_approved:,.0f}")
                k3.metric("Non-bank Share", f"{non_bank_share:.1f}%")
                k4.metric("Avg LTV", f"{avg_ltv:.2f}Ã—")
                k5.metric("Avg DTI", f"{avg_dti:.2f}")
                k6.metric("# Assets", f"{len(df_app)}")

                st.markdown("### ğŸ“ˆ Portfolio Dashboard")
                try:
                    fig_mix = px.pie(df_app, names=decision_col, title="Decision Mix")
                    fig_mix.update_layout(template="plotly_dark", height=300)
                    st.plotly_chart(fig_mix, use_container_width=True)
                except Exception: pass

                try:
                    by_dec = (
                        df_app.groupby(decision_col)[["DTI","LTV"]]
                        .mean(numeric_only=True).reset_index()
                        .melt(id_vars=[decision_col], var_name="metric", value_name="value")
                    )
                    fig_dti_ltv = px.bar(by_dec, x=decision_col, y="value", color="metric",
                                         barmode="group", title="Average DTI / LTV by Decision")
                    fig_dti_ltv.update_layout(template="plotly_dark", height=320)
                    st.plotly_chart(fig_dti_ltv, use_container_width=True)
                except Exception: pass

                st.subheader("ğŸ§¾ AI Decisions (with reasons)")
                st.dataframe(df_app, use_container_width=True)

    # ========== 4) HUMAN REVIEW ==========
    with tab4:
        st.subheader("ğŸ§‘â€âš–ï¸ Stage 4 â€” Human Review & Agreement Score")
        src_choice = st.radio("Use AI output from Stage 3, or import a CSV:", ["Use Stage 3 output","Import CSV"])
        df_rev = None
        if src_choice == "Use Stage 3 output":
            df_rev = ss.get("asset_ai_df")
            if df_rev is None:
                st.warning("No Stage 3 output found. Run appraisal first or import a CSV.")
        else:
            up_rev = st.file_uploader("Upload AI decisions CSV", type=["csv"], key="rev_csv")
            if up_rev is not None:
                df_rev = pd.read_csv(up_rev)

        if df_rev is not None:
            # Ensure columns for human edit
            if "human_decision" not in df_rev.columns:
                df_rev["human_decision"] = df_rev.get("decision", "approved")
            if "human_reason" not in df_rev.columns:
                df_rev["human_reason"] = ""

            st.markdown("**1) Select rows to review and correct**")
            edited = st.data_editor(df_rev, use_container_width=True, key="human_editor")

            st.markdown("**2) Compute agreement score**")
            if st.button("Compute agreement score"):
                ai_col = "decision" if "decision" in edited.columns else "rule_decision"
                ai_vals = edited[ai_col].astype(str).str.lower()
                human_vals = edited["human_decision"].astype(str).str.lower()
                agree = (ai_vals == human_vals)
                agree_pct = float(agree.mean() * 100)
                # Gauge
                gauge = go.Figure(go.Indicator(
                    mode="gauge+number", value=agree_pct,
                    title={'text': "AI â†” Human Agreement"},
                    gauge={'axis': {'range': [0, 100]}, 'bar': {'color': '#22d3ee'},
                           'steps': [{'range': [0, 70], 'color': '#1e293b'},
                                     {'range': [70, 90], 'color': '#0ea5e9'},
                                     {'range': [90, 100], 'color': '#22d3ee'}]}
                ))
                gauge.update_layout(template="plotly_dark", height=260)
                st.plotly_chart(gauge, use_container_width=True)
                # Disagreements table
                dis = edited.loc[~agree, [c for c in edited.columns if c in ["application_id","asset_id","decision","human_decision","ai_reasons","rule_reasons","human_reason"]]]
                st.markdown(f"âŒ **{len(dis)}** rows disagreed out of **{len(edited)}**  ({(1-agree.mean())*100:.1f}% disagreement rate)")
                st.dataframe(dis, use_container_width=True)

                # Export feedback CSV for training
                fname = f"assetappraisal.{ss['asset_user']['name']}.production.{datetime.datetime.utcnow().strftime('%Y%m%d-%H%M%S')}.csv"
                st.download_button("â¬‡ï¸ Export review CSV (for Training tab)",
                                   data=edited.to_csv(index=False).encode("utf-8"),
                                   file_name=fname, mime="text/csv")

                # Persist edited for next tab
                ss["asset_human_feedback_df"] = edited

    # ========== 5) TRAINING (Feedback â†’ Retrain) ==========
    with tab5:
        st.subheader("ğŸ§ª Stage 5 â€” Train from Feedback & Promote to PRODUCTION")

        staged = []
        if "asset_human_feedback_df" in ss and ss["asset_human_feedback_df"] is not None:
            buf = ss["asset_human_feedback_df"].to_csv(index=False).encode("utf-8")
            staged.append(("from_stage4.csv", buf))

        up_fb = st.file_uploader("Upload feedback CSV(s)", type=["csv"], accept_multiple_files=True, key="fb_csvs")
        if up_fb:
            for f in up_fb:
                staged.append((f.name, f.getvalue()))

        if staged:
            st.success(f"Staged {len(staged)} feedback file(s) for training.")
            st.json([name for name, _ in staged])

            # Build a simple JSON payload preview (what we'll send as meta)
            meta = {
                "user_name": ss["asset_user"]["name"],
                "agent_name": "asset_appraisal",
                "algo_name": "asset_lr"  # adjust to your actual backend algo id
            }
            st.markdown("**Launch Retrain â€” payload preview**")
            st.code(json.dumps(meta, indent=2))

            if st.button("ğŸš€ Train candidate model"):
                # POST to training endpoint with files + meta
                files = [("files", (name, io.BytesIO(content), "text/csv")) for name, content in staged]
                data = {"meta": json.dumps(meta)}
                job = None
                for agent_id in ASSET_AGENT_IDS:
                    try:
                        resp = requests.post(f"{API_URL}/v1/agents/{agent_id}/training/train_asset",
                                             files=files, data=data, timeout=180)
                        if resp.ok:
                            job = resp.json(); break
                    except Exception:
                        pass
                if job is None:
                    st.error("Training endpoint failed on all candidate agent ids.")
                else:
                    st.success("Training job submitted.")
                    st.json(job)

            if st.button("ğŸ“ˆ Promote last candidate to PRODUCTION"):
                promoted = None
                for agent_id in ASSET_AGENT_IDS:
                    try:
                        r = requests.post(f"{API_URL}/v1/agents/{agent_id}/training/promote_last", timeout=60)
                        if r.ok:
                            promoted = r.json(); break
                    except Exception:
                        pass
                if promoted:
                    st.success("Model promoted.")
                    st.json(promoted)
                else:
                    st.error("Promotion failed on all candidate agent ids.")

        else:
            st.info("Drop at least one feedback CSV here or generate from Stage 4.")

