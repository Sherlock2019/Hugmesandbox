# services/api/routers/training.py
from fastapi import APIRouter, UploadFile, File, Form, HTTPException
from typing import List, Dict, Any, Optional
from pathlib import Path
import json, time, io, shutil, os
import pandas as pd
import numpy as np

router = APIRouter(prefix="/v1", tags=["training"])

ROOT = Path(__file__).resolve().parents[2]  # services/api -> services -> <ROOT>
STATE_DIR = ROOT / "services" / "api" / ".state"
RUNS_DIR  = ROOT / "services" / "api" / ".runs"
ASSET_TRAINED_DIR   = ROOT / "agents" / "asset_appraisal" / "models" / "trained"
ASSET_PRODUCTION_FP = ROOT / "agents" / "asset_appraisal" / "models" / "production" / "model.joblib"
ASSET_META_FP       = STATE_DIR / "asset_production_meta.json"

STATE_DIR.mkdir(parents=True, exist_ok=True)
RUNS_DIR.mkdir(parents=True, exist_ok=True)
ASSET_TRAINED_DIR.mkdir(parents=True, exist_ok=True)
ASSET_PRODUCTION_FP.parent.mkdir(parents=True, exist_ok=True)

# --- Optional sklearn; fall back to numpy-only model if scipy is unavailable ---
try:
    from sklearn.linear_model import LinearRegression
    import joblib
    _HAVE_SK = True
except Exception:
    _HAVE_SK = False

def _now_tag() -> str:
    return time.strftime("%Y%m%d-%H%M%S")

def _list_trained_models() -> list[Path]:
    if not ASSET_TRAINED_DIR.exists():
        return []
    return sorted(ASSET_TRAINED_DIR.glob("model-*.joblib"), key=lambda p: p.stat().st_mtime, reverse=True)

@router.get("/training/production_meta")
def get_production_meta() -> Dict[str, Any]:
    if ASSET_PRODUCTION_FP.exists():
        meta: Dict[str, Any] = {"version": "1.x", "source": "production"}
        if ASSET_META_FP.exists():
            try:
                meta.update(json.loads(ASSET_META_FP.read_text()))
            except Exception:
                pass
        return {"status": "ok", "has_production": True, "meta": meta}
    return {"status": "ok", "has_production": False, "meta": {}}

@router.post("/agents/{agent_id}/training/train_asset")
async def train_asset_model(
    agent_id: str,
    files: List[UploadFile] = File(..., description="One or more CSV feedback files"),
    meta: Optional[str] = Form(None),
) -> Dict[str, Any]:
    # Validate agent id we support
    if agent_id not in {"asset_appraisal", "asset"}:
        raise HTTPException(status_code=404, detail=f"Unsupported agent '{agent_id}' for train_asset")

    # Read CSVs
    frames: list[pd.DataFrame] = []
    save_dir = RUNS_DIR / f"asset-train-{_now_tag()}"
    save_dir.mkdir(parents=True, exist_ok=True)

    for f in files:
        raw = await f.read()
        (save_dir / f.filename).write_bytes(raw)
        try:
            frames.append(pd.read_csv(io.BytesIO(raw)))
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Failed to parse CSV '{f.filename}': {e}")

    if not frames:
        raise HTTPException(status_code=400, detail="No CSV files provided")

    df = pd.concat(frames, ignore_index=True)

    # Heuristic: predict ai_adjusted (if present), else market_value
    target_col = "ai_adjusted" if "ai_adjusted" in df.columns else ("market_value" if "market_value" in df.columns else None)
    if not target_col:
        raise HTTPException(status_code=422, detail="No target column (ai_adjusted or market_value) found in feedback CSVs")

    # Candidate numeric features
    candidate_feats = [
        "age_years", "condition_score", "legal_penalty", "loan_amount",
        "employment_years", "credit_history_years", "delinquencies",
        "current_loans", "DTI", "LTV"
    ]
    feats = [c for c in candidate_feats if c in df.columns]
    if not feats:
        raise HTTPException(status_code=422, detail=f"No usable numeric features present. Expected any of: {candidate_feats}")

    X = df[feats].apply(pd.to_numeric, errors="coerce").fillna(0.0).values
    y = pd.to_numeric(df[target_col], errors="coerce").fillna(0.0).values

    # Train a tiny model
    model_path = ASSET_TRAINED_DIR / f"model-{_now_tag()}.joblib"
    if _HAVE_SK:
        m = LinearRegression()
        m.fit(X, y)
        joblib.dump({"model": m, "features": feats, "target": target_col}, model_path)
    else:
        # Fallback: pseudo linear fit via normal equation (no scipy)
        X1 = np.c_[np.ones((X.shape[0], 1)), X]
        w  = np.linalg.pinv(X1) @ y
        np.save(model_path.with_suffix(".npy"), {"w": w, "features": feats, "target": target_col})

        # Normalize extension for UI consistency
        model_path = model_path  # keep .joblib name even if content is .npy for now
        shutil.copy2(model_path.with_suffix(".npy"), model_path)

    # Persist job meta
    job_meta = {
        "agent_id": agent_id,
        "saved_model": str(model_path),
        "features": feats,
        "target": target_col,
        "rows": int(df.shape[0]),
        "meta": json.loads(meta) if meta else {},
        "sklearn": _HAVE_SK,
        "ts": _now_tag(),
    }
    (save_dir / "train_meta.json").write_text(json.dumps(job_meta, indent=2))

    return {"status": "ok", "job": job_meta}

@router.post("/agents/{agent_id}/training/promote_last")
def promote_last_model(agent_id: str) -> Dict[str, Any]:
    if agent_id not in {"asset_appraisal", "asset"}:
        raise HTTPException(status_code=404, detail=f"Unsupported agent '{agent_id}' for promote_last")

    models = _list_trained_models()
    if not models:
        raise HTTPException(status_code=404, detail="No trained models found")

    newest = models[0]
    shutil.copy2(newest, ASSET_PRODUCTION_FP)
    meta = {
        "version": "1.x",
        "source": "trained",
        "promoted_from": str(newest),
        "promoted_at": _now_tag(),
    }
    ASSET_META_FP.write_text(json.dumps(meta, indent=2))
    return {"status": "ok", "promoted_to": str(ASSET_PRODUCTION_FP), "meta": meta}
