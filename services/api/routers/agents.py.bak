# services/api/routers/agents.py
from __future__ import annotations

import io
import os
import json
import time
from typing import Any, Dict

import numpy as np
import pandas as pd
from fastapi import APIRouter, UploadFile, File, Request, HTTPException

router = APIRouter(tags=["credit_agent"])

AGENT_NAME = "credit_appraisal"
RUNS_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".runs"))
os.makedirs(RUNS_ROOT, exist_ok=True)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _parse_form_to_params(form: Dict[str, Any]) -> Dict[str, Any]:
    params: Dict[str, Any] = {}
    for k, v in form.items():
        if isinstance(v, UploadFile) or k == "file":
            continue
        if isinstance(v, (list, tuple)):
            params[k] = ",".join(map(str, v))
        else:
            params[k] = str(v)
    return params


def _load_csv_from_upload(upload: UploadFile | None) -> pd.DataFrame:
    if upload is None:
        raise HTTPException(status_code=400, detail="CSV file is required (multipart/form-data with 'file').")
    try:
        content = upload.file.read()
        return pd.read_csv(io.BytesIO(content))
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Could not parse CSV: {e}") from e


def _ensure_run_dir(run_id: str) -> str:
    run_dir = os.path.join(RUNS_ROOT, AGENT_NAME, run_id)
    os.makedirs(run_dir, exist_ok=True)
    return run_dir


def _json_safe(obj: Any, max_str: int = 10_000) -> Any:
    if isinstance(obj, pd.DataFrame):
        return {"type": "dataframe", "shape": list(obj.shape), "columns": list(map(str, obj.columns))}
    if isinstance(obj, pd.Series):
        return {"type": "series", "length": int(obj.shape[0]), "name": str(obj.name)}
    if isinstance(obj, (np.integer,)): return int(obj)
    if isinstance(obj, (np.floating,)): return float(obj)
    if isinstance(obj, (np.bool_,)): return bool(obj)
    if isinstance(obj, dict): return {str(k): _json_safe(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple)): return [_json_safe(v) for v in obj]
    if isinstance(obj, (bytes, bytearray)): return obj.decode("utf-8", errors="replace")[:max_str]
    if isinstance(obj, str): return obj[:max_str]
    if isinstance(obj, (int, float, bool)) or obj is None: return obj
    return repr(obj)[:max_str]


def _persist_minimal_artifacts(run_id: str, result: Dict[str, Any]) -> None:
    run_dir = _ensure_run_dir(run_id)
    merged_path = os.path.join(run_dir, "merged.csv")
    summary_path = os.path.join(run_dir, "summary.json")

    # Try saving merged.csv if present in result
    if not os.path.exists(merged_path):
        merged_df = None
        if isinstance(result, dict):
            for key in ("merged_df", "merged", "results_df"):
                if isinstance(result.get(key), pd.DataFrame):
                    merged_df = result.get(key)
                    break
        if isinstance(merged_df, pd.DataFrame):
            merged_df.to_csv(merged_path, index=False)

    # ðŸ”¹ Auto-create summary.json fallback for report API
    if not os.path.exists(summary_path):
        try:
            if os.path.exists(merged_path):
                df = pd.read_csv(merged_path)
                summary = {
                    "agent": AGENT_NAME,
                    "rows": len(df),
                    "columns": list(df.columns),
                    "stats": {
                        "min": float(df.select_dtypes("number").min().min()) if not df.empty else None,
                        "mean": float(df.select_dtypes("number").mean().mean()) if not df.empty else None,
                        "max": float(df.select_dtypes("number").max().max()) if not df.empty else None,
                    },
                }
                with open(summary_path, "w", encoding="utf-8") as f:
                    json.dump(summary, f, indent=2)
        except Exception as e:
            print(f"[WARN] Could not write summary.json: {e}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Route â€” Credit Agent Runner
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@router.post("/v1/agents/{agent_name}/run")
async def run_agent(agent_name: str, request: Request, file: UploadFile | None = File(None)) -> Dict[str, Any]:
    if agent_name != AGENT_NAME:
        raise HTTPException(status_code=404, detail=f"Unknown agent '{agent_name}'")

    try:
        form = await request.form()
    except Exception:
        form = {}

    params = _parse_form_to_params(form)
    df = _load_csv_from_upload(file)

    # Import the credit agent module dynamically
    try:
        from agents.credit_appraisal import agent as credit_agent
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to import agent: {e}") from e

    fallback_run_id = f"run_{int(time.time())}"

    try:
        if hasattr(credit_agent, "run"):
            raw_result = credit_agent.run(df, params)
        elif hasattr(credit_agent, "run_credit_appraisal"):
            raw_result = credit_agent.run_credit_appraisal(df, **params)
        else:
            raise AttributeError("No valid run() or run_credit_appraisal() in credit agent")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Agent execution failed: {e}") from e

    run_id = (raw_result or {}).get("run_id") or fallback_run_id

    _persist_minimal_artifacts(run_id, raw_result or {})
    return {"run_id": run_id, "result": _json_safe(raw_result or {})}
